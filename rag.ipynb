{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_hdd_16t/miniconda3/envs/dd-chat/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import openai\n",
    "import chromadb\n",
    "import warnings\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Document, VectorStoreIndex, get_response_synthesizer, StorageContext, QueryBundle\n",
    "from llama_index.core.retrievers import VectorIndexRetriever, BaseRetriever\n",
    "from llama_index.core.node_parser import SemanticDoubleMergingSplitterNodeParser, LanguageConfig\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from typing import Literal, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from context_cite import ContextCiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = 'documents/attention.pdf'\n",
    "MODEL_NAME = \"Llama-3.2-1B-Instruct\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\" # 3.2 1B Instruct for faster inference, 3.1 8B for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "config = LanguageConfig(language=\"english\", spacy_model=\"en_core_web_md\") # must download the model first\n",
    "embed_model = OpenAIEmbedding()\n",
    "splitter = SemanticDoubleMergingSplitterNodeParser(\n",
    "    initial_threshold=0.6,\n",
    "    appending_threshold=0.5,\n",
    "    merging_threshold=0.6,\n",
    "    language_config=config,\n",
    "    max_chunk_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_TOKEN\"),\n",
    "    num_workers=8,\n",
    "    show_progress=True,\n",
    "    result_type=\"markdown\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"documents/intro_to_ml.pdf\"\n",
    "if not os.path.exists(file):\n",
    "    raise FileNotFoundError(f\"File {file} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b2b81d8b-3bef-4a11-90e6-c6264e38dec0\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 640/640 [01:46<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = parser.load_data(file)\n",
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1024/1024 [00:23<00:00, 43.57it/s]\n",
      "Generating embeddings: 100%|██████████| 1024/1024 [00:22<00:00, 45.05it/s]\n",
      "Generating embeddings: 100%|██████████| 919/919 [00:15<00:00, 58.72it/s]\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "vector_index = VectorStoreIndex(nodes=nodes, \n",
    "                         insert_batch_size=1024, \n",
    "                         storage_context=storage_context,\n",
    "                         show_progress=True)                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5)\n",
    "sparse_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=5)\n",
    "\n",
    "res_synth = get_response_synthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRetriever(BaseRetriever):\n",
    "    def __init__(self, dense_retriever: BaseRetriever = dense_retriever, \n",
    "                 sparse_retriever: BaseRetriever = sparse_retriever,\n",
    "                 mode: Literal[\"AND\", \"OR\"] = \"OR\",\n",
    "                 **kwargs) -> None:\n",
    "        self.dense_retriever = dense_retriever\n",
    "        self.sparse_retriever = sparse_retriever\n",
    "        self.mode = mode\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        dense_res = self.dense_retriever.retrieve(query_bundle)\n",
    "        sparse_res = self.sparse_retriever.retrieve(query_bundle)\n",
    "\n",
    "        dense_ids = {n.node.node_id for n in dense_res}\n",
    "        sparse_ids = {n.node.node_id for n in sparse_res}\n",
    "\n",
    "        combined_ids = {n.node.node_id: n for n in dense_res}\n",
    "        combined_ids.update({n.node.node_id: n for n in sparse_res})\n",
    "\n",
    "        if self.mode == \"AND\":\n",
    "            ids = dense_ids.intersection(sparse_ids)\n",
    "\n",
    "        elif self.mode == \"OR\":\n",
    "            ids = dense_ids.union(sparse_ids)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Must be either 'AND' or 'OR'.\")\n",
    "        \n",
    "        retrieved_nodes = [combined_ids[id] for id in ids]\n",
    "        return retrieved_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = HybridRetriever(dense_retriever=dense_retriever, sparse_retriever=sparse_retriever)\n",
    "query_engine = RetrieverQueryEngine(retriever=hybrid_retriever, response_synthesizer=res_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(query, nodes,\n",
    "           model=model_name,\n",
    "           long=False,\n",
    "           top_k=None):\n",
    "    context = \"\\n\\n\".join([node.node.get_content() for node in nodes])\n",
    "    \n",
    "    cc = ContextCiter.from_pretrained(\n",
    "        model_name,\n",
    "        context=context,\n",
    "        query=query,\n",
    "        device=\"cuda\",\n",
    "        solver=\"elastic_net\",\n",
    "        num_ablations=128\n",
    "    )\n",
    "\n",
    "    attributions = cc.get_attributions(as_dataframe=True, top_k=len(nodes) if top_k is None else top_k)\n",
    "    \n",
    "    if hasattr(attributions, \"data\"):\n",
    "        attributions_df = attributions.data\n",
    "    else:\n",
    "        attributions_df = attributions\n",
    "\n",
    "    segments = cc.sources\n",
    "    score_list = attributions_df[\"Score\"].tolist()\n",
    "\n",
    "    node_scores = {}\n",
    "    for node in nodes:\n",
    "        node_text = node.node.get_content()\n",
    "        cumulative_score = 0.0\n",
    "        for seg, score in zip(segments, score_list):\n",
    "            if seg.strip() and seg.strip() in node_text:\n",
    "                cumulative_score += score\n",
    "        node_scores[node.node.node_id] = cumulative_score\n",
    "\n",
    "    reranked_nodes = sorted(nodes, key=lambda x: node_scores.get(x.node.node_id, 0.0), reverse=True)\n",
    "    return reranked_nodes, cc.response, node_scores, attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pdf(query: str, top_k: int = 5) -> list:\n",
    "    \"\"\" \n",
    "    Query the PDF document using the query engine.\"\n",
    "    \"\"\"\n",
    "    global query_engine, nodes\n",
    "    if query_engine is None:\n",
    "        return \"Please upload a PDF first.\"\n",
    "\n",
    "    long = True if len(nodes) > 100 else False\n",
    "    rnodes = query_engine.retriever.retrieve(QueryBundle(query))\n",
    "    reranked_nodes, cc_response, node_scores, attrs = rerank(query, rnodes)\n",
    "    \n",
    "    top_nodes = reranked_nodes[:top_k]  \n",
    "    final_context = \"\\n\\n\".join([node.node.get_content() for node in top_nodes])\n",
    "    \n",
    "    final_response = (\n",
    "        f\"{cc_response}\\n\\nTop Ranked Context:\\n{final_context}\\n\\nNode Scores:\\n{node_scores}\"\n",
    "    )\n",
    "\n",
    "    if hasattr(attrs, \"data\"):\n",
    "        attrs = attrs.data\n",
    "    \n",
    "    return final_response, attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributed: Machine learning is a branch of artificial intelligence that enables computers to learn and improve their performance on a task without being explicitly programmed. It involves training algorithms to recognize patterns, make predictions, or take actions based on data, allowing machines to adapt to new situations and improve their performance over time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:13<00:00,  9.22it/s]\n"
     ]
    }
   ],
   "source": [
    "res, attributions = query_pdf(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.341433</td>\n",
       "      <td>Machine learning also helps us find solutions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.912308</td>\n",
       "      <td>Contents Preface xvii 1.1 What Is Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.784766</td>\n",
       "      <td>To be intelligent, a system that is in a chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.166246</td>\n",
       "      <td>At the same time, we know that a face image is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.977079</td>\n",
       "      <td>If the system can learn and adapt to such chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.648020</td>\n",
       "      <td>In science, large amounts of data in physics, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.607022</td>\n",
       "      <td>But machine learning is not just a database pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.594878</td>\n",
       "      <td>Because we are not able to explain our experti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score                                             Source\n",
       "0  15.341433  Machine learning also helps us find solutions ...\n",
       "1   6.912308  Contents Preface xvii 1.1 What Is Machine Lear...\n",
       "2   2.784766  To be intelligent, a system that is in a chang...\n",
       "3   1.166246  At the same time, we know that a face image is...\n",
       "4   0.977079  If the system can learn and adapt to such chan...\n",
       "5   0.648020  In science, large amounts of data in physics, ...\n",
       "6   0.607022  But machine learning is not just a database pr...\n",
       "7   0.594878  Because we are not able to explain our experti..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning also helps us find solutions to many problems in vision, speech recognition, and robotics.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions.iloc[0].Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contents Preface xvii 1.1 What Is Machine Learning? 1 1.2 Examples of Machine Learning Applications 4 1.2.1 Learning Associations 4 1.2.4 Unsupervised Learning 11 2.1 Learning a Class from Examples 21 2.7 Model Selection and Generalization 37 2.8 Dimensions of a Supervised Machine Learning Algorithm 41 “Learning Logical Definitions from Relations.” Machine Learning 5:239–266. “An Introduction to MCMC for Machine Learning.” Machine Learning 50:5–43. “Q-learning.” Machine Learning 8:279–292. 1.1 What Is Machine Learning? abundant: In addition to retail, in finance banks analyze their past data to build models to use in credit applications, fraud detection, and the stock market.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions.iloc[1].Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
