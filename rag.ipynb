{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import chromadb\n",
    "import warnings\n",
    "import nest_asyncio\n",
    "import re\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Document, VectorStoreIndex, get_response_synthesizer, StorageContext, QueryBundle\n",
    "from llama_index.core.retrievers import VectorIndexRetriever, BaseRetriever\n",
    "from llama_index.core.node_parser import SemanticDoubleMergingSplitterNodeParser, LanguageConfig\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from typing import Literal, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from context_cite import ContextCiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "config = LanguageConfig(language=\"english\", spacy_model=\"en_core_web_md\") # must download the model first\n",
    "# chroma_client = chromadb.PersistentClient()\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "\n",
    "splitter = SemanticDoubleMergingSplitterNodeParser(\n",
    "    initial_threshold=0.7,\n",
    "    appending_threshold=0.9,\n",
    "    merging_threshold=0.9,\n",
    "    language_config=config,\n",
    "    max_chunk_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMACLOUD_API_KEY\"),\n",
    "    num_workers=8,\n",
    "    show_progress=True,\n",
    "    result_type=\"markdown\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = 'documents/attention.pdf'\n",
    "MODEL_NAME = \"Llama-3.2-1B-Instruct\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\" # 3.2 1B Instruct for faster inference, 3.1 8B for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"documents/sample.pdf\"\n",
    "if not os.path.exists(file):\n",
    "    raise FileNotFoundError(f\"File {file} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id ff54eafc-90b6-4bc0-be54-f35ac6cf92e4\n"
     ]
    }
   ],
   "source": [
    "documents = parser.load_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 6/6 [00:04<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted 156 nodes from 6 documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Splitted {len(nodes)} nodes from {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 156/156 [00:04<00:00, 38.99it/s]\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "vector_index = VectorStoreIndex(nodes=nodes, \n",
    "                         insert_batch_size=1024, \n",
    "                         storage_context=storage_context,\n",
    "                         show_progress=True)                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=5)\n",
    "sparse_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=5)\n",
    "\n",
    "res_synth = get_response_synthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRetriever(BaseRetriever):\n",
    "    def __init__(self, dense_retriever: BaseRetriever = dense_retriever, \n",
    "                 sparse_retriever: BaseRetriever = sparse_retriever,\n",
    "                 mode: Literal[\"AND\", \"OR\"] = \"OR\",\n",
    "                 **kwargs) -> None:\n",
    "        self.dense_retriever = dense_retriever\n",
    "        self.sparse_retriever = sparse_retriever\n",
    "        self.mode = mode\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        dense_res = self.dense_retriever.retrieve(query_bundle)\n",
    "        sparse_res = self.sparse_retriever.retrieve(query_bundle)\n",
    "\n",
    "        dense_ids = {n.node.node_id for n in dense_res}\n",
    "        sparse_ids = {n.node.node_id for n in sparse_res}\n",
    "\n",
    "        combined_ids = {n.node.node_id: n for n in dense_res}\n",
    "        combined_ids.update({n.node.node_id: n for n in sparse_res})\n",
    "\n",
    "        if self.mode == \"AND\":\n",
    "            ids = dense_ids.intersection(sparse_ids)\n",
    "\n",
    "        elif self.mode == \"OR\":\n",
    "            ids = dense_ids.union(sparse_ids)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Must be either 'AND' or 'OR'.\")\n",
    "        \n",
    "        retrieved_nodes = [combined_ids[id] for id in ids]\n",
    "        return retrieved_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = HybridRetriever(dense_retriever=dense_retriever, sparse_retriever=sparse_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine(retriever=hybrid_retriever, response_synthesizer=res_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The printf function in C stands for \"print formatted\".', source_nodes=[NodeWithScore(node=TextNode(id_='f4473641-2231-4849-b303-3f7e59c22bb6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='625cb19c-85ae-4d86-b682-9216d001ca8a', node_type='4', metadata={}, hash='7281de5e65e0e3f21640a18ddd2b4d8ebaa323e2f4c8ee0944d16d88f714d3b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8535b86c-2565-4e8f-9344-82b41de2d930', node_type='1', metadata={}, hash='133890adeb5751af16b25aafc46442c5134fdd7c67201059a7c43761edea6302'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b4c154c8-54eb-465d-a54d-9dbb26fc34b8', node_type='1', metadata={}, hash='ec33d5af67c1f45e55be0d7c25aaf1e7c4cd9ad5442a6b936fa96da3f286032a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='- \"Unsung Heroes of IT: Part One: Brian Kernighan\".', mimetype='text/plain', start_char_idx=957, end_char_idx=1008, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.0), NodeWithScore(node=TextNode(id_='c79216bc-2121-4a23-a4b2-626ca2d8344d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e5193125-ed45-4e5c-a2cb-e77aec0f0697', node_type='4', metadata={}, hash='d364b86c1eda48f57328591fea539d30e060716bac2077fd8d2c393536542676'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='46505d6a-179e-4e33-ae73-3efadf678aed', node_type='1', metadata={}, hash='2b8af945f7d84969c07a6d76665c1b80af9fc4cc4284b10c46d8a9befd515420'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dbae27c1-24f3-487d-8615-3c2f33d5d4fd', node_type='1', metadata={}, hash='e7d95915c74f07f336d0a1713e1aba7c807f6605a19cfd0cea87563101c60b2e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\"Programming in C: A Tutorial\" (PDF).', mimetype='text/plain', start_char_idx=1657, end_char_idx=1694, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8179900822576958), NodeWithScore(node=TextNode(id_='23e27ad4-9f4a-483b-b2b6-190f7145d752', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2fe3befb-616e-4d89-ba31-e43b7acb2255', node_type='4', metadata={}, hash='0e21741e5655b2140ca5424d788011fde501d9208075dbc9f3fbbe54b3e7d3dc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e3b4926b-ebfd-4010-af25-5b6ffcb45c11', node_type='1', metadata={}, hash='df52a54b3ccbd0ec9ba10bbc4065e5efafff74e29ef312976bfb9ce83eccbfe9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='152a9c40-0f57-47b4-959f-e61b67319b56', node_type='1', metadata={}, hash='73f2fde1c4dd867927506d34905e7e483656da68ec8b223126c89b9f8d9e6d73')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"*n');\\n}\\na 'hell';\\nb 'o, w';\\nc 'orld';\\n\\nThe program above prints hello, world!\", mimetype='text/plain', start_char_idx=1755, end_char_idx=1832, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8094627062215697), NodeWithScore(node=TextNode(id_='14117c19-8b1a-45d1-8803-f26ab0221854', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='625cb19c-85ae-4d86-b682-9216d001ca8a', node_type='4', metadata={}, hash='7281de5e65e0e3f21640a18ddd2b4d8ebaa323e2f4c8ee0944d16d88f714d3b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f3a1b7c-d577-4aa8-b67c-368499113379', node_type='1', metadata={}, hash='dd59246a7eea58eab3f539ccf36db5ef9c2026206c0dd0d7ffd4ff38b291f79a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='46ab27ff-0d92-4646-b2fa-3a1c24b4835d', node_type='1', metadata={}, hash='17d035803d75d0e18114e106a8da26412deaa5326652a138e21a171983fe12aa')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Retrieved 23 August 2014.', mimetype='text/plain', start_char_idx=1122, end_char_idx=1147, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.0), NodeWithScore(node=TextNode(id_='14762540-868b-4d20-ae7a-328620766def', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2fe3befb-616e-4d89-ba31-e43b7acb2255', node_type='4', metadata={}, hash='0e21741e5655b2140ca5424d788011fde501d9208075dbc9f3fbbe54b3e7d3dc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='0a0156c2-f502-4dd4-9468-6993a027474b', node_type='1', metadata={}, hash='da3b31ba797dbe383339b6c38060c118d5b5ee9df02cea39375730dcef134c3a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b4357cae-5c77-4c62-81a0-84e5b19e7e86', node_type='1', metadata={}, hash='7f5e520fd1f480c7fc6a6e39a67447d4d64372b4352c6d41aa202d14f38eb4eb')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The example program from the book prints \"hello, world\", and was inherited from a 1974 Bell Laboratories internal memorandum by Brian Kernighan, Programming in C: A Tutorial*:3\\n\\nmain( ) {\\nprintf(\"hello, world\");\\n}\\n\\nIn the above example, the main( ) function defines where the \"Hello, World!\"', mimetype='text/plain', start_char_idx=897, end_char_idx=1188, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8385149836540222), NodeWithScore(node=TextNode(id_='e3b4926b-ebfd-4010-af25-5b6ffcb45c11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2fe3befb-616e-4d89-ba31-e43b7acb2255', node_type='4', metadata={}, hash='0e21741e5655b2140ca5424d788011fde501d9208075dbc9f3fbbe54b3e7d3dc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b4357cae-5c77-4c62-81a0-84e5b19e7e86', node_type='1', metadata={}, hash='7f5e520fd1f480c7fc6a6e39a67447d4d64372b4352c6d41aa202d14f38eb4eb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='23e27ad4-9f4a-483b-b2b6-190f7145d752', node_type='1', metadata={}, hash='2036882499f36a3d94a801aa6617ac45bfbc45247f59f32b1b5f6415b435e302')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='The function body consists of a single statement, a call to the printf() function, which stands for \"print formatted\"; it outputs to the console whatever is passed to it as the parameter, in this case the string \"hello, world\". The C-language version was preceded by Kernighan\\'s own 1972 *A Tutorial Introduction to the Language B*,4 where the first known version of the program is found in an example used to illustrate external variables:\\n\\nmain( ) {\\nextrn a, b, c;\\nputchar(a); putchar(b); putchar(c); putchar(\\'!', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5951758027076721), NodeWithScore(node=TextNode(id_='46ab27ff-0d92-4646-b2fa-3a1c24b4835d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='625cb19c-85ae-4d86-b682-9216d001ca8a', node_type='4', metadata={}, hash='7281de5e65e0e3f21640a18ddd2b4d8ebaa323e2f4c8ee0944d16d88f714d3b6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='14117c19-8b1a-45d1-8803-f26ab0221854', node_type='1', metadata={}, hash='5aceaa65495e4aec84b5d2034bc98a3b0dcd209ab6c29f23c1ae273525aa0b96')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Retrieved from https://en.wikipedia.org/w/index.php?title=%22Hello,_World!%22_program&oldid=1274895481', mimetype='text/plain', start_char_idx=1149, end_char_idx=1251, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.0), NodeWithScore(node=TextNode(id_='ee6c307e-3e99-46a6-8762-776ae608bae9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e8f33f73-638d-4906-a5f5-66d59d794f99', node_type='4', metadata={}, hash='450dc31e630cb4ccdc9e9a0423fb3adc410c465d1e0e1912589228578e6410f6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6a9a5734-e6db-4b1d-927b-8af4c6e7069a', node_type='1', metadata={}, hash='7943a12aa0712d8090b3873449d5220c967d644c2a0e4bcbc45c56b5a6480ecd'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='85358e13-c6a1-4f57-bf5e-1caae6fc8980', node_type='1', metadata={}, hash='c3666d355ee145aa8cbd04a051d5f450f274af5914182dffed2de28f11fa8912')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='In contrast, the equivalent code in C++7 requires the import of the input/output (I/O) software library, the manual declaration of an entry point, and the explicit instruction that the output string should be sent to the standard output stream.', mimetype='text/plain', start_char_idx=799, end_char_idx=1043, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.806665031776644)], metadata={'f4473641-2231-4849-b303-3f7e59c22bb6': {}, 'c79216bc-2121-4a23-a4b2-626ca2d8344d': {}, '23e27ad4-9f4a-483b-b2b6-190f7145d752': {}, '14117c19-8b1a-45d1-8803-f26ab0221854': {}, '14762540-868b-4d20-ae7a-328620766def': {}, 'e3b4926b-ebfd-4010-af25-5b6ffcb45c11': {}, '46ab27ff-0d92-4646-b2fa-3a1c24b4835d': {}, 'ee6c307e-3e99-46a6-8762-776ae608bae9': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = query_engine.query(\"What does printf mean in C?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(query, nodes,\n",
    "           model=model_name,\n",
    "           top_k=5):\n",
    "    context = \"\\n\\n\".join([node.node.get_content() for node in nodes])\n",
    "    \n",
    "    cc = ContextCiter.from_pretrained(\n",
    "        model_name,\n",
    "        context=context,\n",
    "        query=query,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    attributions = cc.get_attributions(as_dataframe=False, top_k=len(nodes))\n",
    "    segments = cc.sources\n",
    "\n",
    "    node_scores = {}\n",
    "    for node in nodes:\n",
    "        node_text = node.node.get_content()\n",
    "        cumulative_score = 0.0\n",
    "        # For each source segment and its associated attribution score,\n",
    "        # if the segment appears in the node's text, add its score.\n",
    "        for seg, score in zip(segments, attributions):\n",
    "            if seg.strip() and seg.strip() in node_text:\n",
    "                cumulative_score += score\n",
    "        node_scores[node.node.node_id] = cumulative_score\n",
    "\n",
    "    # Re-rank the nodes by descending cumulative score.\n",
    "    reranked_nodes = sorted(nodes, key=lambda x: node_scores.get(x.node.node_id, 0.0), reverse=True)\n",
    "    \n",
    "    return reranked_nodes, cc.response, node_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pdf(query):\n",
    "    global query_engine\n",
    "    if query_engine is None:\n",
    "        return \"Please upload a PDF first.\"\n",
    "\n",
    "    nodes = query_engine.retriever.retrieve(QueryBundle(query))\n",
    "    reranked_nodes, cc_response, node_scores = rerank(query, nodes)\n",
    "    \n",
    "    top_nodes = reranked_nodes[:5]  # select the top 5 nodes\n",
    "    final_context = \"\\n\\n\".join([node.node.get_content() for node in top_nodes])\n",
    "    \n",
    "    final_response = (\n",
    "        f\"{cc_response}\\n\\nTop Ranked Context:\\n{final_context}\\n\\nNode Scores:\\n{node_scores}\"\n",
    "    )\n",
    "    \n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mquery_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the purpose of the printf function in C?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mquery_pdf\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPlease upload a PDF first.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m nodes = query_engine.retriever.retrieve(QueryBundle(query))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m reranked_nodes, cc_response, node_scores = \u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m top_nodes = reranked_nodes[:\u001b[32m5\u001b[39m]  \u001b[38;5;66;03m# select the top 5 nodes\u001b[39;00m\n\u001b[32m     10\u001b[39m final_context = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([node.node.get_content() \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m top_nodes])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrerank\u001b[39m\u001b[34m(query, nodes, model, top_k)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrerank\u001b[39m(query, nodes,\n\u001b[32m      2\u001b[39m            model=model_name,\n\u001b[32m      3\u001b[39m            top_k=\u001b[32m5\u001b[39m):\n\u001b[32m      4\u001b[39m     context = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([node.node.get_content() \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     cc = \u001b[43mContextCiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     attributions = cc.get_attributions(as_dataframe=\u001b[38;5;28;01mFalse\u001b[39;00m, top_k=\u001b[38;5;28mlen\u001b[39m(nodes))\n\u001b[32m     14\u001b[39m     segments = cc.sources\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Battlefield\\IAILab\\code\\context_cite\\context_citer.py:111\u001b[39m, in \u001b[36mContextCiter.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, context, query, solver, device, model_kwargs, tokenizer_kwargs, quantized, **kwargs)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    108\u001b[39m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m    109\u001b[39m         pretrained_model_name_or_path, **model_kwargs\n\u001b[32m    110\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m    113\u001b[39m     pretrained_model_name_or_path, **tokenizer_kwargs\n\u001b[32m    114\u001b[39m )\n\u001b[32m    115\u001b[39m tokenizer.padding_side = \u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\modeling_utils.py:3110\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3106\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3107\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3108\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3109\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1323\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1324\u001b[39m             device,\n\u001b[32m   1325\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1326\u001b[39m             non_blocking,\n\u001b[32m   1327\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1328\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tsunn\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "query_pdf(\"What is the purpose of the printf function in C?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
